apply(w,dnorm)
apply(w,FUN=dnorm)
sapply(w,dnorm)
library(foreach)
?foreach
install.packages("tm",dependencies=T)
2->a
a
1<->2
install.packages("lavaan",dependencies=T)
library(lavaan)
data(PoliticalDemocracy)
summary(PoliticalDemocracy)
install.packages("proto",dependiencies=T)
install.packages("proto",dependencies=T)
statnet
libarary(statnet)
library(statnet)
data(samplike)
samlike
data(samplik)
library(statnet)
data(samlike)
data()
samplike
samplke
samplk
data(samplike)
data(samplk)
samplk
summary(samplk)
samplk1
library("ROAuth", dependencies=T)
install.packages("ROAuth", dependencies=T)
k<-0
tapply(1:10^7,function(x) k<-k+x)
?tapply
apply(1:10^7,function(x) k<-k+x)
apply(1:10^7,FUN=function(x) k<-k+x)
X<-1L10^7
X<-1^10^7
length(X)
k
lapply(1:10^7,function(x) k<-k+x)
h<-apply(1:10^7,function(x) k<-k+x)
?sapply
h<-sapply(1:10^7,function(x) k<-k+x)
h[1]
length(h)
# File-Name:       speed_test.R                 #
# Date:            2010-06-04                                #
# Author:          Drew Conway                                       #
# Purpose:         #
# Data Used:       #
# Packages Used:          #
# Output File:     #
# Data Output:     #
# Machine:         Drew Conway's MacBook                         #
                                                                    #
# Ex1#
k<-0#
print(system.time(sapply(1:10^7,function(i) k<-k+i)))
# File-Name:       speed_test.R                 #
# Date:            2010-06-04                                #
# Author:          Drew Conway                                       #
# Purpose:         #
# Data Used:       #
# Packages Used:          #
# Output File:     #
# Data Output:     #
# Machine:         Drew Conway's MacBook                         #
                                                                    #
# Ex1#
k<-0#
ex1<-function(x) {#
    for(i in 1:10^7) {#
        x<-x+i#
    }#
}#
print(system.time(ex1(k)))
k<-0#
print(system.time(apply(X=1:10^7,FUN=function(x) k<-k+x)))
dim(1:10^7)
?apply
# File-Name:       speed_test.R                 #
# Date:            2010-06-04                                #
# Author:          Drew Conway                                       #
# Purpose:         #
# Data Used:       #
# Packages Used:          #
# Output File:     #
# Data Output:     #
# Machine:         Drew Conway's MacBook                         #
                                                                    #
# Ex1#
k<-0#
print(system.time(1:10^7,1,function(x) k<-k+x)))
# File-Name:       speed_test.R                 #
# Date:            2010-06-04                                #
# Author:          Drew Conway                                       #
# Purpose:         #
# Data Used:       #
# Packages Used:          #
# Output File:     #
# Data Output:     #
# Machine:         Drew Conway's MacBook                         #
                                                                    #
# Ex1#
k<-0#
print(system.time(1:10^7,1,function(x) k<-k+x))
# File-Name:       speed_test.R                 #
# Date:            2010-06-04                                #
# Author:          Drew Conway                                       #
# Purpose:         #
# Data Used:       #
# Packages Used:          #
# Output File:     #
# Data Output:     #
# Machine:         Drew Conway's MacBook                         #
                                                                    #
# Ex1#
k<-0#
print(system.time(1:10^7,function(x) k<-k+x))
k<-0#
print(system.time(apply(1:10^7,function(x) k<-k+x)))
# File-Name:       speed_test.R                 #
# Date:            2010-06-04                                #
# Author:          Drew Conway                                       #
# Purpose:         #
# Data Used:       #
# Packages Used:          #
# Output File:     #
# Data Output:     #
# Machine:         Drew Conway's MacBook                         #
                                                                    #
# Ex1#
k<-0#
print(system.time(apply(1:10^7,FUN=function(x) k<-k+x)))
k<-0#
print(system.time(apply(1:10^7,1,FUN=function(x) k<-k+x)))
install.packages("foreach",dependencies=T)
library(foreach)
?foreach
k<-0
foreach(i=1:10^7) %do% k<-k+i
foreach(i=1:3) %do%#
  sqrt(i)
foreach(i=1:10^7) %do%
k<-k+i
foreach(i=1:10^7) %do%
function(i) k<-k+i
library(Hmisc)
install.packages("Hmsic",dependencies=T)
install.packages("Hmisc",dependencies=T)
library(Hmisc)
install.packages("rjags",dependencies=T)
library(rjags)
install.packages("rjags")
install.packages("tm")
install.packages("tm",dependencies=T)
?library
install.packages("ggplot2",dependencies=T)
require(maps)
library(ggplot2)
nz <- data.frame(map("af", plot=FALSE)[c("x","y")])
nz <- data.frame(map("ag", plot=FALSE)[c("x","y")])
nz <- data.frame(map("Afghanistan", plot=FALSE)[c("x","y")])
nz <- data.frame(map("afghanistan", plot=FALSE)[c("x","y")])
?maps
nz <- data.frame(map("nz", plot=FALSE)[c("x","y")])
nz
nz <- data.frame(map("af", plot=FALSE)[c("x","y")])
(nzmap <- qplot(x, y, data=nz, geom="path"))
?mapproject
library(maptools)
?mapproject
?maptools
map_data("af")
map_data("Afghanistan")
?map_data
reg <- as.data.frame(map("world", xlim = -c(37.3, 29.4), ylim = c(75.0,60.6), plot = FALSE)[c("x", "y")])
reg <- as.data.frame(map("world", ylim = -c(37.3, 29.4), xlim = c(75.0,60.6), plot = FALSE)[c("x", "y")])
library(ff)
?ff
174*10^1
demo()
revo()
library(topicmodel)
library(topicmodels)
?vcov
const<-rep(1:3,10)
const
m<-rnorm(3)
m
sapply(const,function(i), m[i])
sapply(const,function(i) m[i])
?match
?autoload
library(multicore)
?mclapply
import stats
library(stats)
plnorm(100,log(130), log(10))
plnorm(1,log(130), log(10))
curve(function(x) plnorm(x, log(130),log(10)))
?curve
curve(function(x) plnorm(x, log(130),log(10)),from=0,to=10000)
?curve
curve(function(x) {plnorm(x, log(130),log(10))},from=0,to=10000)
curve(function(x) {plnorm(x, log(130),log(10))},from=1,to=10000)
curve(function(x) {plnorm(x, log(130),log(10))},0,10000)
curve(cosa,0,10000)
curve(cos,0,10000)
f<-function(x) {plnorm(x, log(130),log(10))}
f
f(1)
curve(f,0,10000)
dlnorm(100,log(130),log(10))
f<-function(x) {dlnorm(x, log(130),log(10))}
curve(f,0,10000)
f<-function(x) {dlnorm(x, log(130),log(20))}
curve(f,0,10000)
library(ggplot)
library(ggplot2)
ggplot(as.data.frame(1:100000),aes(V1))+stat_function(fun=f)
as.data.frame(1:100)
ggplot(as.data.frame(1:100000),aes(1:100000)+stat_function(fun=f)+theme_bw()
)
ggplot(as.data.frame(1:100000),aes(1:100000))+stat_function(fun=f)+theme_bw()
f
ggplot(as.data.frame(1:100000),aes(1:100000))+geom_density()+stat_function(fun=f)+theme_bw()
ggplot(as.data.frame(1:100000),aes(1:100000))+stat_function(fun=f)+theme_bw()
x<-1:100000
qplot(x)+stat_function(fun-f)
qplot(x)+stat_function(fun=f)
?as
library(ggplot2)#
library(spatstat)#
library(maptools)#
#
#
to_ppp <- function(long,lat,win){#
    as.ppp(ppp(long,lat,window=win))#
}#
load("afg.data")#
#
afg <- afg.data#
spatstat.options(checkpolygons = FALSE) #
afg$data <- afg$data[!is.na(afg$data$Latitude),]#
#
######## Everything above run before presentation#
#
data = subset(afg$data, Type=="Friendly Fire" & DateOccurred > as.Date("2009-01-01"))#
win = as(afg$outline,"owin")#
points = to_ppp(data$Longitude, data$Latitude, win)#
d = density(points,0.2)#
#
img = t(as.matrix(d))#
df = expand.grid(x=d$xcol, y=d$yrow)#
df$z = melt(img)$value#
#
p = ggplot(df, aes(x=x,y=y))#
p + geom_tile(aes(fill=z))+theme_bw()
library(ggplot2)#
library(spatstat)#
library(maptools)#
#
#
to_ppp <- function(long,lat,win){#
    as.ppp(ppp(long,lat,window=win))#
}#
load("afg.data")#
#
afg <- afg.data#
spatstat.options(checkpolygons = FALSE) #
afg$data <- afg$data[!is.na(afg$data$Latitude),]
data.frame(0:nrow(dd)
)
ls
quit()
library(infochimps)
chimps<-infochimps("vv5cbsDQRvWcuwAhgfiXkLHLx69")
strong.links("drewconway",chimps)
library(igraph)
G<-graph.data.frame(strong.links("drewconway",ses))
G<-graph.data.frame(strong.links("drewconway",chimps))
G
summary(G)
e
?new.env
?.onLoad
h$data<-list()
h<-new.env()
h$data<-list()
h$dat
h$data
h
h$data<-list(cocks="big",tits=)
h$data<-list(cocks="big",tits="massive")
h$data$cocks
library(twitteR)#
library(infochimps)#
library(datamap)#
#
infochimps('vv5cbsDQRvWcuwAhgfiXkLHLx69')#
#
# Creates a new mapper, similar to an OO class#
newMapper(type='twitchimps:influence',#
#
    # Init is called once during newMap(). Note that#
    # since it's called only once, your friend list, wether you#
    # add or drop some later, will stay constant.#
    init = function(map,user){#
        install(#
            unlist(lapply(userFriends(user), function(n) screenName(n))),#
            map#
        )#
        TRUE#
    },#
#
    # Get is called real-time on each access to the variable#
    get = function(user) influence(user)#
)#
#
#
# Install the map at position 2 on the search path#
mapAttach(newMap('twitchimps:influence','YOUR_TWITTER_NAME_HERE'),pos=2)#
#
# List all your friends#
ls(2)
install.packages("datamap",dependencies=TRUE)
library(twitteR)#
library(infochimps)#
library(datamap)#
#
infochimps('vv5cbsDQRvWcuwAhgfiXkLHLx69')#
#
# Creates a new mapper, similar to an OO class#
newMapper(type='twitchimps:influence',#
#
    # Init is called once during newMap(). Note that#
    # since it's called only once, your friend list, wether you#
    # add or drop some later, will stay constant.#
    init = function(map,user){#
        install(#
            unlist(lapply(userFriends(user), function(n) screenName(n))),#
            map#
        )#
        TRUE#
    },#
#
    # Get is called real-time on each access to the variable#
    get = function(user) influence(user)#
)#
#
#
# Install the map at position 2 on the search path#
mapAttach(newMap('twitchimps:influence','YOUR_TWITTER_NAME_HERE'),pos=2)#
#
# List all your friends#
ls(2)
install.packages("twitteR",dependencies=TRUE)
library(twitteR)#
library(infochimps)#
library(datamap)#
#
infochimps('vv5cbsDQRvWcuwAhgfiXkLHLx69')#
#
# Creates a new mapper, similar to an OO class#
newMapper(type='twitchimps:influence',#
#
    # Init is called once during newMap(). Note that#
    # since it's called only once, your friend list, wether you#
    # add or drop some later, will stay constant.#
    init = function(map,user){#
        install(#
            unlist(lapply(userFriends(user), function(n) screenName(n))),#
            map#
        )#
        TRUE#
    },#
#
    # Get is called real-time on each access to the variable#
    get = function(user) influence(user)#
)#
#
#
# Install the map at position 2 on the search path#
mapAttach(newMap('twitchimps:influence','YOUR_TWITTER_NAME_HERE'),pos=2)#
#
# List all your friends#
ls(2)
library(twitteR)#
library(infochimps)#
library(datamap)
library(twitteR)#
library(infochimps)#
library(datamap)#
#
infochimps('vv5cbsDQRvWcuwAhgfiXkLHLx69')#
#
# Creates a new mapper, similar to an OO class#
newMapper(type='twitchimps:influence',#
#
    # Init is called once during newMap(). Note that#
    # since it's called only once, your friend list, wether you#
    # add or drop some later, will stay constant.#
    init = function(map,user){#
        install(#
            unlist(lapply(userFriends(user), function(n) screenName(n))),#
            map#
        )#
        TRUE#
    },#
#
    # Get is called real-time on each access to the variable#
    get = function(user) influence(user)#
)#
#
#
# Install the map at position 2 on the search path#
mapAttach(newMap('twitchimps:influence','drewconway'),pos=2)#
#
# List all your friends#
ls(2)
ls()
ls(1)
ls(2)
library(twitteR)#
library(infochimps)#
library(datamap)#
#
infochimps('vv5cbsDQRvWcuwAhgfiXkLHLx69')#
#
# Creates a new mapper, similar to an OO class#
newMapper(type='twitchimps:influence',#
#
    # Init is called once during newMap(). Note that#
    # since it's called only once, your friend list, wether you#
    # add or drop some later, will stay constant.#
    init = function(map,user){#
        install(#
            unlist(lapply(userFriends(user), function(n) screenName(n))),#
            map#
        )#
        TRUE#
    },#
#
    # Get is called real-time on each access to the variable#
    get = function(user) influence(user)#
)#
#
#
# Install the map at position 2 on the search path#
mapAttach(newMap('twitchimps:influence','drewconway'),pos=2)#
#
# List all your friends#
ls(2)#
#
# Their names are now variables. Enter one at the R prompt and see that#
# it contains their infochimps influence.#
#
# Create a data frame. You may want to use head(ls(2)) instead of ls(2)#
# if you have quite a few followers.#
#
x <- data.frame()#
lapply(#
    ls(2),#
    function(i){#
        y <- get(i)#
        if(!is.na(y))#
            x <<- rbind(x,as.data.frame(y))#
    }#
)#
#
summary(x)
exp((21-1.1*log(1563)))
library(liglimn)
library(biglm)
?biglm
library("twitteR")
publicTimeline()
t<-publicTimeline()
20*20
20*25
publicTimeline(500)
?publicTimeline
library(tm)
pub.time<-publicTimeline(n=500()
)
pub.time<-publicTimeline(n=500)
pub.time<-publicTimeline()
pub.time<-sapply(1:25,fuction(x) publicTimeline)
publicTimeline(n=100)
rand.pub<-list()
for(i in 1:500) { rand.pub[[i]]<-publicTimeline(n=1)}
rand.pub
?append
rand.pub<-list()
setwd('/Users/agconway/Desktop/WikiLeaks_Analysis')
# File-Name:       wikileaks_analysis.R                 #
# Date:            2010-07-26                                #
# Author:          Drew Conway#
# Email:           drew.conway@nyu.edu                                      #
# Purpose:         Load and format WikiLeaks data, to be loaded in the header of all subsequent files#
# Data Used:       afg.csv (http://leakmirror.wikileaks.org/file/straw-glass-and-bottle/afg-war-diary.csv.7z)#
# Packages Used:   ggplot2,plyr,maptools,Zelig,#
# Output File:     #
# Data Output:     #
# Machine:         Drew Conway's MacBook Pro#
#
# Copyright (c) 2010, under the Simplified BSD License.  #
# For more information on FreeBSD see: http://www.opensource.org/licenses/bsd-license.php#
# All rights reserved.                                                         #
#
# For data manipulation and visualization#
library(ggplot2)#
library(plyr)#
library(maptools)#
library(RColorBrewer)#
#
library(spatstat)#
library(geoR)#
library(maptools)#
library(mapproj)#
#
# For models#
# library(geoR)#
# library(topicmodels)#
#
# Shapefile directory#
shape.files<-"shapefiles/"#
#
### DATA CLEAN ####
#
# This will take several seconds on most laptops#
cat("reading data\n")#
afg<-read.csv("~/Dropbox/Wikileaks_project/Wikidata/afg.csv",stringsAsFactors=FALSE)#
#
# Add header data leftout by WikiLeaks, label reference taken from http://wardiary.wikileaks.org/#
colnames(afg)<-c("ReportKey","DateOccurred","Type","Category","TrackingNumber","Title","Summary","Region","AttackOn",#
    "ComplexAttack","ReportingUnit","UnitName","TypeOfUnit","FriendlyWIA","FriendlyKIA","HostNationWIA","HostNationKIA",#
    "CivilianWIA","CivilianKIA","EnemyWIA","EnemyKIA","EnemyDetained","MGRS","Latitude","Longitude","OriginatorGroup",#
    "UpdatedByGroup","CCIR","Sigact","Affiliation","DColor","Classification")#
#
cat("converting date\n")    #
# Convert date to R format#
afg$DateOccurred <- as.Date(afg$DateOccurred)#
year <- format.Date(afg$DateOccurred,"%Y")#
#
# Collapse bad region data#
afg$Region[grep("RC ",afg$Region,fixed=T,invert=T)]<-"UNKNOWN"#
afg$Region<-as.factor(afg$Region)#
#
# Aggregate WIA and KIA data into new columns#
all.wia<-afg$FriendlyWIA+afg$HostNationWIA+afg$CivilianWIA+afg$EnemyWIA#
all.kia<-afg$FriendlyKIA+afg$HostNationKIA+afg$CivilianKIA+afg$EnemyKIA#
all.cas<-all.wia+all.kia#
#
# Create a new column to identify where Summary column includes the word 'contractor'#
has.cntr<-rep(FALSE,nrow(afg))#
has.cntr[grep("contractor",afg$Summary,fixed=FALSE,ignore.case=TRUE)]<-TRUE#
#
# Add new columns to afg dataframe#
afg<-transform(afg,AllKIA=all.kia,AllWIA=all.wia,AllCasualty=all.cas,Year=year,HasCntr=has.cntr)#
#
#
# rough lat/lon limits of Afghanistan:#
max_lat = max(afg.poly$lat)#
min_lat = min(afg.poly$lat)#
max_lon = max(afg.poly$lon)#
min_lon = min(afg.poly$lon)#
#
# filter out events not in Afghanistan (?!)#
to_keep <- (afg$lat > min_lat) & (afg$lat < max_lat) & (afg$lon > min_lon) & (afg$lon < max_lon)#
afg_ts <- afg[to_keep,]#
#
# filter out NA events#
to_throw <- is.na(afg_ts$type)#
afg_ts <- afg_ts[!to_throw,]
setwd('/Users/agconway/Desktop/WikiLeaks_Analysis')
# File-Name:       wikileaks_analysis.R                 #
# Date:            2010-07-26                                #
# Author:          Drew Conway#
# Email:           drew.conway@nyu.edu                                      #
# Purpose:         Load and format WikiLeaks data, to be loaded in the header of all subsequent files#
# Data Used:       afg.csv (http://leakmirror.wikileaks.org/file/straw-glass-and-bottle/afg-war-diary.csv.7z)#
# Packages Used:   ggplot2,plyr,maptools,Zelig,#
# Output File:     #
# Data Output:     #
# Machine:         Drew Conway's MacBook Pro#
#
# Copyright (c) 2010, under the Simplified BSD License.  #
# For more information on FreeBSD see: http://www.opensource.org/licenses/bsd-license.php#
# All rights reserved.                                                         #
#
# For data manipulation and visualization#
library(ggplot2)#
library(plyr)#
library(maptools)#
library(RColorBrewer)#
#
library(spatstat)#
library(geoR)#
library(maptools)#
library(mapproj)#
#
# For models#
# library(geoR)#
# library(topicmodels)#
#
# Shapefile directory#
shape.files<-"shapefiles/"#
#
### DATA CLEAN ####
#
# This will take several seconds on most laptops#
cat("reading data\n")#
afg<-read.csv("~/Dropbox/Wikileaks_project/Wikidata/afg.csv",stringsAsFactors=FALSE)#
#
# Add header data leftout by WikiLeaks, label reference taken from http://wardiary.wikileaks.org/#
colnames(afg)<-c("ReportKey","DateOccurred","Type","Category","TrackingNumber","Title","Summary","Region","AttackOn",#
    "ComplexAttack","ReportingUnit","UnitName","TypeOfUnit","FriendlyWIA","FriendlyKIA","HostNationWIA","HostNationKIA",#
    "CivilianWIA","CivilianKIA","EnemyWIA","EnemyKIA","EnemyDetained","MGRS","Latitude","Longitude","OriginatorGroup",#
    "UpdatedByGroup","CCIR","Sigact","Affiliation","DColor","Classification")#
#
cat("converting date\n")    #
# Convert date to R format#
afg$DateOccurred <- as.Date(afg$DateOccurred)#
year <- format.Date(afg$DateOccurred,"%Y")#
#
# Collapse bad region data#
afg$Region[grep("RC ",afg$Region,fixed=T,invert=T)]<-"UNKNOWN"#
afg$Region<-as.factor(afg$Region)#
#
# Aggregate WIA and KIA data into new columns#
all.wia<-afg$FriendlyWIA+afg$HostNationWIA+afg$CivilianWIA+afg$EnemyWIA#
all.kia<-afg$FriendlyKIA+afg$HostNationKIA+afg$CivilianKIA+afg$EnemyKIA#
all.cas<-all.wia+all.kia#
#
# Create a new column to identify where Summary column includes the word 'contractor'#
has.cntr<-rep(FALSE,nrow(afg))#
has.cntr[grep("contractor",afg$Summary,fixed=FALSE,ignore.case=TRUE)]<-TRUE#
#
# Add new columns to afg dataframe#
afg<-transform(afg,AllKIA=all.kia,AllWIA=all.wia,AllCasualty=all.cas,Year=year,HasCntr=has.cntr)#
#
# Load shapefiles#
# Afghanistan adminstrative file#
afg.shp <- readShapePoly(paste(shape.files,"admin/admin3_poly_32.shp",sep=""))#
afg.poly <- fortify.SpatialPolygons(afg.shp)#
#
#
# rough lat/lon limits of Afghanistan:#
max_lat = max(afg.poly$lat)#
min_lat = min(afg.poly$lat)#
max_lon = max(afg.poly$lon)#
min_lon = min(afg.poly$lon)#
#
# filter out events not in Afghanistan (?!)#
to_keep <- (afg$lat > min_lat) & (afg$lat < max_lat) & (afg$lon > min_lon) & (afg$lon < max_lon)#
afg_ts <- afg[to_keep,]#
#
# filter out NA events#
to_throw <- is.na(afg_ts$type)#
afg_ts <- afg_ts[!to_throw,]
summary(afg_ts)
summary(afg)
setwd('/Users/agconway/Desktop/WikiLeaks_Analysis')
# filter out events not in Afghanistan (?!)#
to_keep <- (afg$lat > min_lat) & (afg$lat < max_lat) & (afg$lon > min_lon) & (afg$lon < max_lon)#
afg_ts <- afg[to_keep,]
summary(afg_ts)
to_keep
setwd('/Users/agconway/Desktop/WikiLeaks_Analysis')
afg_boundary<-subset(afg, lat>=min_lat & lat<=max_lat & lon>=min_lon & lon<=max_lon)
setwd('/Users/agconway/Desktop/WikiLeaks_Analysis')
afg_boundary<-subset(afg, Latitude>=min_lat & Latitude<=max_lat & Longitude>=min_lon & Longitude<=max_lon)
summary(afg)
nrow(afg_boundary)
unique(afg_boundary$Type)
setwd('/Users/agconway/Desktop/WikiLeaks_Analysis')
afg_ied<-subset(afg_boundary, type=="Explosive Hazard")
setwd('/Users/agconway/Desktop/WikiLeaks_Analysis')
afg_ied<-subset(afg_boundary, Type=="Explosive Hazard")
nrow(afg_ied)
summary(afg_ied)
setwd('/Users/agconway/Desktop/WikiLeaks_Analysis')
afg_count<-ddply(afg_ied,.(Year,Latitude,Longitude), summarise, Count=nrow)
summary(afg_count)
afg_count
setwd('/Users/agconway/Desktop/WikiLeaks_Analysis')
afg_count<-ddply(afg_ied,.(Year,Latitude,Longitude), nrow)
summary(afg_count)
?summarise
summarise(afg_ied,.(Year,Latitude,Longitude), Count=nrow)
?transform
afg_count[which(afg_count$V1== 10604.000)]
afg_count[which(afg_count$V1==10604.000),]
